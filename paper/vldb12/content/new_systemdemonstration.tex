\section{Text Analysis Queries and Demonstration}
Our demonstration will illustrate the following points: 
\begin{enumerate}
  \item The ability to perform statistical text analytics inside the DBMS
  \item Query driven computation of analytics
  \item The flexibility of our data sources by using structured data and text
  \item Query execution over large amounts of text in real-time
  \item Ability to perform textual analytics across multiple domains
\end{enumerate} 

\subsection{Dataset for Example}
Our sample demonstration for MADden involves a variety of NFL based data sources. 
The data is represented in Table \ref{tab:madschema} as an abbreviated
schema\footnote{These tables may be extracted to an RDBMS, or defined over an
API using a foreign data wrapper (fdw).}.

The {\tt NFLCorpus} table holds blogs
and news articles crawled from the web, as well as tweets extracted using the
Twitter Streaming API with a series of NFL related keywords. These documents
vary in size and quality, with some potential out-of domain documents (mainly
tweets). Each document holds a \textit{doc\_id}, \textit{doc\_type},
\textit{text}, associated tags, and document metadata.

The other tables are more structured,
including {\tt PlayerStats2011\_*}, with * indicating passing ({\tt Pass}), Receiving ({\tt
Rec}), Rushing ({\tt Rush}), Special Teams ({\tt ST}), or Defense ({\tt Def}).
This data was extracted from the NFL.com player database. Each table contains
the player's \textit{name}, \textit{position}, \textit{number}, and a series of
stats corresponding to the stat type (Some players show up in multiple tables, others in only one). The
{\tt Player} table holds information about a player in the NFL, including
\textit{college}, \textit{birthday}, \textit{height}, \textit{weight}, as well
as \textit{years\_in\_NFL}. The {\tt Team} table holds some basic information
about the 32 NFL teams, including \textit{location}, \textit{conference}, \textit{division}, and \textit{stadium}.
{\tt TeamStats\_2011} holds the team rankings and stats in a vareity of categories (Offense, Defense, Special Teams,
Points, etc.).
{\tt Extracted\_Entities} can either be a view or table, and it stores the
extracted entities found in the {\tt NFLCorpus} documents.

\begin{table}
\begin{center}
\begin{tabular}{|l|l|}
\hline
\multicolumn{2}{|c|}{Example Schema}\\
\hline
$NFLCorpus$ & Documents table\\
\hline
$PlayerStats2011\_*$ & Player Stats tables for 2011\\
\hline
$Player$ & Basic Player information\\
\hline
$Team\_Stats2011$ & Total Team stats and rankings\\
\hline
$Team$ & Basic Team information \\
\hline
$Extracted\_Entities$ & View/Table of entities and documents \\
\hline
\end{tabular}
\end{center}
\caption{Listing of current MADden functions}
\label{tab:madschema}
\end{table}

\subsection{Text Analytics Queries}
Based on our example dataset, suppose a sports journalist
wants to do an investigative piece on overall public opinion 
of all the Florida NFL teams during the 2011-2012 season. 
Such a peice would require in-depth analysis of news reports,
tweets, blog postings, among other sources. On the text
analytics side of this problem, the standard approach would
consist of trawling through the text sources either by hand
with help, or utilizing a series of different text processing
toolkits and packages, sometimes specialized for a singular 
task. MADden can streamline this process, with its declarative,
in-database approach to text analytics. A first step could 
conceivably consist of paring your corpora down to just
the documents ``related'' to the Florida football teams, namely
the Miami Dolphins, Jacksonville Jaguars, and Tampa Bay Buccaneers. 

%\lstset{breaklines=true}
%\lstset{tabsize=2}
%\lstset{basicstyle=\small}
%\begin{lstlisting}{language=SQL}
\begin{small}
\begin{alltt}
\textit{Q1: Entity Resolution}
SELECT DISTINCT doc_id
FROM extracted_entities
WHERE match('Jaguars', entity) > match\_thresh
   OR match('Dolphins', entity) > match\_thresh
   OR match('Buccaneers', entity) > match\_thresh;
\end{alltt}
\end{small}
%\end{lstlisting}


We note that $match(target, against)$, is an Entity
Resolution UDF, and ExtractedEntities is a view constructed 
using an Entity Recognition function on textual documents as they
are added to the database (In this case, likely news articles and blogs). A
table of all current text analysis functions can be seen in
\ref{tab:madfunct}. \\

\begin{table}
\begin{center}
\begin{tabular}{|l|l|}
\hline
\multicolumn{2}{|c|}{Current MADden Functions}\\
\hline
$match(target, against)$ & Entity Resolution\\
\hline
$sentiment(text)$ & Sentiment Analysis\\
\hline
$entity\_find(text, boolean)$ & Detects Named Entities\\
\hline
$pos\_tag(text)$ & POS tagging\\
\hline
$pos\_extract(text, type)$ & POS term extraction \\
\hline
\end{tabular}
\end{center}
\caption{Listing of current MADden functions}
\label{tab:madfunct}
\end{table}

Maybe the journalist wants to explore fan sentiment for the Jacksonville Jaguars
based on tweets collected during the NFL season. Utilizing the first 
query as a building block (with some changes), we can construct this 
query as follows:

%\lstset{breaklines=true}
%\lstset{tabsize=2}
%\lstset{basicstyle=\small}
%\begin{lstlisting}{language=SQL}
\begin{small}
\begin{alltt}
\textit{Q2: Entity Resolution and Sentiment Analysis}
SELECT DISTINCT E.docid, E.entity, sentiment(S.document)
FROM extracted_entities as E, NFLCorpus as S
WHERE E.doc_id = S.doc_id
  AND sentiment(S.document) in ('+', '-')
  AND match('Jaguars', E.entity) > match\_thresh
  AND S.type = 'tweet';
\end{alltt}
\end{small}
%\end{lstlisting}

In this case, one could accomodate for nicknames through OR-matching
the extracted entities, an alias table, among other strategies. Notice
that going from a singular text analytics task, to a somewhat more 
complex analysis only required a small change in our SQL query. 
Whereas a traditional approach would have us either looking for a
customized solution or patching together packages, the declarative
sql approach allows the user to just state what the result is.

And since we are working in SQL, we can combine queries on corpus 
tables with tables of structured data. For example, if our journalist
wants to analyze the media opinion of the state's best reciever,
he could consult both the player stats table, as well as the media blogs:

%\lstset{breaklines=true}
%\lstset{tabsize=2}
%\lstset{basicstyle=\small}
%\begin{lstlisting}{language=SQL}
\begin{small}
\begin{alltt}
\textit{Q3: Structured & Unstructured}
SELECT BestWR.name, sentiment(A.txt)
FROM NFLCorpus A, extracted_entities E,
         (SELECT P.fname || ' ' || P.lname as name
          FROM PlayerStats2011_Rec P
          WHERE P.team = 'Jaguars' 
             OR P.team = 'Dolphins' 
             OR P.team = 'Buccaneers'
          ORDER BY P.rec_yds DESC, P.recs ASC
          LIMIT 1) as BestWR
WHERE E.doc_id = A.doc_id 
  AND (A.type = 'blog' OR A.type = 'news')
  AND match(BestWR.name, E.entity) > match\_thresh;
\end{alltt}
\end{small}
%\end{lstlisting}


\subsection{User Interface}


During the conference, we plan to give an interactive demonstration of the 
{\system}'s capabilities.
We built a user interface to allow the user to interact with \system. 
We will allow the user to use tables from our NFL data set or political data
for campaign management queries.


For the demonstration, a web interface will be provided to interact with our
system. It will utilize both a raw SQL UI, as well as a Mad
Lib\footnote{http://en.wikipedia.org/wiki/Mad\_Libs} style interface. The raw
SQL interface will allow users to type in their own SQL queries to interact with
the datasets, while the Mad Libs interface will allow users to customize query
templates through drop-down lists and text box completions.

Regardless of the interaction type, results from the queries will be presented 
to the user through a vareity of visualizations

